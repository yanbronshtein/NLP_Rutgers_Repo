{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignment requires you to compute the TF-IDF measures for words in a collection of documents or corpus. TF-IDF stands for Term Frequency-Inverse Document Frequency and measures the relevance of a term <i><b>t</b></i> (t can be a word or a sequence of words called an n-gram) for a document in a collection. It is a combination of two measures as follows:\n",
    "\n",
    "1. Term Frequency (TF) measures the frequency of the term t in a document d. If the term occurs n times in a document, then TF is usually the normalized frequency and is defined as:\n",
    "\n",
    "\tTF(t, d) = n/(number of terms in d)\n",
    "\n",
    "If the TF measure is high, then the term occurs frequently in the document and is considered relevant for that document. \n",
    "\n",
    "2. Inverse Document Frequency (IDF) is\n",
    "\n",
    "\tIDF(t) = log(total number of documents/number of documents containing t)\n",
    "\n",
    "IDF measures how important a term is in the collection. Terms such as \"and\" and \"the\" may occur across all documents and are not considered relevant. So, the IDF value for such terms will be low. \n",
    "\n",
    "Finally, TF-IDF(t, d) = TF(t,d) * IDF(t)\n",
    "\n",
    "For an example, see the example section at http://www.tfidf.com  . \n",
    "\n",
    "Your corpus could be a single file where each line or paragraph is a document or it could be a directory \n",
    "with multiple files where each file is a document. See the attached hw1-input.txt for a trivial example of two documents. Each line is a document here and a newline character is the indication for the end of the document. We will use this example to illustrate the computation of TF-IDF. \n",
    "\n",
    "You may choose to represent the document collection as a Python list of strings in your program. See the code cell below for a representation of the two documents in hw1-input.txt. We will refer to this document collection as the <i><b>sample document collection</b></i> in this homework. \n",
    "\n",
    "IMPORTANT:\n",
    "\n",
    "(1) You need to strip out ALL punctuation and convert words to lowercase in your program.\n",
    "\n",
    "(2)<b> You cannot use any Python library that computes the TF-IDF scores. </b>\n",
    "    \n",
    "(3) <b>  You are required to use NumPy arrays and the functions/techniques discussed in class to find the denominators in the TF and IDF measures in Parts III and IV </b> (number of terms in document and number of documents containing t). If you use naive loops to count these measures, you will lose points. Both these measures require you to compute something across the rows/columns. Think of which aggregate functions you could you use in NumPy to do this easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_document_collection = ['The car is driven on the road', 'The truck is driven on the highway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_document_collection) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I  - 10 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function called doc_vocab that takes a document corpus (could be a filename or a directory name with multiple files in it. You can assume the former for simplicity.) and returns a (1) vocabulary of words for the corpus and (2) the document collection (a list of documents). \n",
    "\n",
    "You can implement the vocabulary as a dictionary where the key is the word and the value (to which the key is mapped) is a unique index assigned to the word. \n",
    "\n",
    "The dictionary for the sample document collection could be something like \n",
    "{'the': 0, 'car': 1, 'is': 2, 'driven': 3, 'on': 4, 'road': 5, 'truck': 6, 'highway': 7}\n",
    "\n",
    "Note that the actual indices you have could be different. They just have to be unique and consecutive i.e. for n words in the dictionary, the indices should range from 0 to n-1. Also note that words \"the\" and \"The\" are assumed to be the same.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART I: build lexicon and document collection\n",
    "def doc_vocab(filename):\n",
    "    collection = list(); lexicon = dict(); line_counter = 0; #limit=2\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.translate(str.maketrans('', '', string.punctuation)).lower().strip()            \n",
    "            collection.append(line)\n",
    "            tokenized_sent = line.split()\n",
    "            for word in tokenized_sent:\n",
    "                if word not in lexicon:\n",
    "                    lexicon[word] = len(lexicon)\n",
    "    \n",
    "            \n",
    "    # you may import libraries and define additional helper functions outside this function\n",
    "    # lexicon is a synonym for vocabulary\n",
    "    \n",
    "    return lexicon, collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - 20 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function called <i><b>doc_term_matrix</i></b> that takes a vocabulary and a document collection as parameters and returns a document term matrix. This matrix should be a two-dimensional NumPy array with the following shape: (number of documents in collection, number of terms in vocabulary). For the sample document collection, the array's shape will be (2, 8). If the array is M, then M[i, j] will contain the number of times term j occurs in document i. For the sample document collection, you may get something like \n",
    "\n",
    "[[2 1 1 1 1 1 0 0]\n",
    "\n",
    " [2 0 1 1 1 0 1 1]] . \n",
    "\n",
    "Note that the columns may be arranged differently based on the indices for the terms in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 2\n",
      "key: 1\n",
      "is: 1\n",
      "in: 1\n",
      "car: 1\n"
     ]
    }
   ],
   "source": [
    "# You will need to initialize a NumPy array to store the document term matrix. \n",
    "# Which NumPy function will you use for this? What are the dimensions of this matrix?\n",
    "# Fill this NumPy array with the appropriate values and return it as the value for this function\n",
    "#You may use the collections package to count the number of times an element occurs in a list. \n",
    "#Note a use of collections below. You can modify it for use in Part II\n",
    "import collections\n",
    "dictfreq = collections.Counter(\"the key is in the car\".split())\n",
    "\n",
    "for key in dictfreq.keys():\n",
    "    print(key+\": \"+str(dictfreq[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART II: document term matrix\n",
    "\n",
    "#nrows: number of documents\n",
    "#ncols: number of unique words\n",
    "def doc_term_matrix(vocabulary, collection):\n",
    "    # fill in your code here\n",
    "    freq = np.zeros((len(collection), len(vocabulary)))\n",
    "    for i in range(len(collection)):\n",
    "        dictfreq = collections.Counter(collection[i].split()) #get frequency counts for all rows\n",
    "        for key in dictfreq.keys():\n",
    "            vocab_idx = vocabulary[key] #Get index of vocab word to know new coordinates in matrix\n",
    "            freq[i, vocab_idx] = dictfreq[key]\n",
    "    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III - 20 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function called <i><b>tf_matrix</i></b> that takes a document term matrix and returns a normalized frequency matrix that represents the TF scores for each term in each document. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART III: normalized document term matrix\n",
    "# Again, initialize a NumPy array with the appropriate dimensions and \n",
    "# then fill it with the appropriate values.\n",
    "# You must use a NumPy aggregation function for computing the TF scores\n",
    "# Think about making your code succinct.\n",
    "def row_norm(row):    \n",
    "    return row/np.nansum(row)\n",
    "\n",
    "def tf_matrix(document_term_matrix):\n",
    "    norm_freq = np.apply_along_axis(row_norm, axis=1, arr=document_term_matrix) \n",
    "    \n",
    "    return norm_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV - 20 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function called <i><b>tf_idf_matrix</i></b> that takes a document term matrix and a normalized frequency matrix and returns a matrix that represents the TF-IDF scores for each term in the document. You can use np.log10 to compute the logarithm here. For the sample document collection, the function could return something like \n",
    "\n",
    "[[0.0 &nbsp;  0.04300429 &nbsp; 0.0 &nbsp; 0.0  &nbsp;  0.0 &nbsp;  0.04300429 &nbsp;   0.0 &nbsp;  0.0 &nbsp;]\n",
    "  \n",
    " [0.0 &nbsp; 0.0 &nbsp;  0.0 &nbsp;  0.0 &nbsp;  0.0 &nbsp;  0.0 &nbsp; 0.04300429 &nbsp; 0.04300429 &nbsp;]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART IV: TF_IDF matrix\n",
    "\n",
    "def tf_idf_matrix(document_term_matrix, tf_matrix):\n",
    "    idf_mat = np.log10(len(document_term_matrix)/np.count_nonzero(document_term_matrix, axis=0))\n",
    "    return np.multiply(tf_matrix, idf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part V - 10 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to test your functions for the trivial test case: hw1-input.txt. \n",
    "You must print out \n",
    "\n",
    "(1) the vocabulary\n",
    "\n",
    "(2) the document frequency matrix\n",
    "\n",
    "(3) the normalized frequency matrix\n",
    "\n",
    "(4) the tf-idf matrix \n",
    "\n",
    "\n",
    "Label each output with what it is. E.g. VOCABULARY, DOCUMENT FREQUENCY MATRIX, and so on.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) The vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'car': 1,\n",
       " 'is': 2,\n",
       " 'driven': 3,\n",
       " 'on': 4,\n",
       " 'road': 5,\n",
       " 'truck': 6,\n",
       " 'highway': 7}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab, collection = doc_vocab('hw1-input.txt')\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) The document frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 1., 1., 1., 1., 1., 0., 0.],\n",
       "       [2., 0., 1., 1., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_mat = doc_term_matrix(vocabulary=vocab, collection=collection)\n",
    "doc_term_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) The normalized frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28571429, 0.14285714, 0.14285714, 0.14285714, 0.14285714,\n",
       "        0.14285714, 0.        , 0.        ],\n",
       "       [0.28571429, 0.        , 0.14285714, 0.14285714, 0.14285714,\n",
       "        0.        , 0.14285714, 0.14285714]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_mat = tf_matrix(doc_term_mat)\n",
    "tf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) The tf-idf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.04300429, 0.        , 0.        , 0.        ,\n",
       "        0.04300429, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04300429, 0.04300429]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = tf_idf_matrix(doc_term_mat, tf_mat)\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part VI - 20 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test your code with a more complex input file(s). You may use <b><i>beatles_biography.txt</b></i> taken from https://www.notablebiographies.com/Ba-Be/Beatles.html. In this case, the documents could be defined by the newlines in the file. You are free to collapse the paragraphs to create fewer documents. You may also use other documents about the Beatles to do a broader analysis or you can choose a set of documents about a different topic. This part of the assignment is open-ended. \n",
    "\n",
    "Using the aggregate functions in NumPy, print out the maximum tf-idf scores for each document and their corresponding words. Note that it may be interesting to pick a few top words (words that have tf-idf scores close to the maximum). \n",
    "\n",
    "You can choose to (1) have a list of stop words to filter the documents and (2) have a list of words (say, 1-3 words i.e. n-grams) for each term instead of a single word. You may have to modify your function definitions in this case. Show your modified functions in this section. This part is optional and for extra credit only.\n",
    "\n",
    "Explain your methods clearly and write your observations from your experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: Your submission must be an Jupyter Notebook (.ipynb) file that is organized exactly like this notebook file. You can insert cells (or use the cells provided) after the instructions for each section in this file and then insert your code into the cells. To write your observations for Part VI, change the type of the cell to Markdown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in': 0,\n",
       " 'the': 1,\n",
       " '1960s': 2,\n",
       " 'a': 3,\n",
       " 'new': 4,\n",
       " 'band': 5,\n",
       " 'known': 6,\n",
       " 'as': 7,\n",
       " 'beatles': 8,\n",
       " 'burst': 9,\n",
       " 'on': 10,\n",
       " 'pop': 11,\n",
       " 'music': 12,\n",
       " 'scene': 13,\n",
       " 'and': 14,\n",
       " 'changed': 15,\n",
       " 'it': 16,\n",
       " 'forever': 17,\n",
       " 'members': 18,\n",
       " 'included': 19,\n",
       " 'george': 20,\n",
       " 'harrison': 21,\n",
       " '1943–2001': 22,\n",
       " 'john': 23,\n",
       " 'lennon': 24,\n",
       " '1940–1980': 25,\n",
       " 'paul': 26,\n",
       " 'mccartney': 27,\n",
       " '1942–': 28,\n",
       " 'ringo': 29,\n",
       " 'starr': 30,\n",
       " '1940–': 31,\n",
       " 'with': 32,\n",
       " 'release': 33,\n",
       " 'of': 34,\n",
       " 'three': 35,\n",
       " 'anthologies': 36,\n",
       " 'collections': 37,\n",
       " 'mid1990s': 38,\n",
       " 'remain': 39,\n",
       " 'one': 40,\n",
       " 'bestselling': 41,\n",
       " 'musical': 42,\n",
       " 'groups': 43,\n",
       " 'all': 44,\n",
       " 'time': 45,\n",
       " 'came': 46,\n",
       " 'from': 47,\n",
       " 'liverpool': 48,\n",
       " 'england': 49,\n",
       " 'were': 50,\n",
       " 'originally': 51,\n",
       " 'inspired': 52,\n",
       " 'by': 53,\n",
       " 'simple': 54,\n",
       " 'guitarandwashboard': 55,\n",
       " 'style': 56,\n",
       " 'skiffle': 57,\n",
       " 'was': 58,\n",
       " 'lively': 59,\n",
       " 'type': 60,\n",
       " 'acoustic': 61,\n",
       " 'nonelectric': 62,\n",
       " 'that': 63,\n",
       " 'used': 64,\n",
       " 'songs': 65,\n",
       " 'british': 66,\n",
       " 'american': 67,\n",
       " 'folk': 68,\n",
       " 'popular': 69,\n",
       " 'later': 70,\n",
       " 'such': 71,\n",
       " 'us': 72,\n",
       " 'artists': 73,\n",
       " 'elvis': 74,\n",
       " 'presley': 75,\n",
       " '1935–1977': 76,\n",
       " 'buddy': 77,\n",
       " 'holly': 78,\n",
       " '1936–1959': 79,\n",
       " 'little': 80,\n",
       " 'richard': 81,\n",
       " '1932–': 82,\n",
       " 'influenced': 83,\n",
       " 'them': 84,\n",
       " 'four': 85,\n",
       " 'had': 86,\n",
       " 'an': 87,\n",
       " 'early': 88,\n",
       " 'interest': 89,\n",
       " 'started': 90,\n",
       " 'when': 91,\n",
       " 'formed': 92,\n",
       " 'his': 93,\n",
       " 'own': 94,\n",
       " 'group': 95,\n",
       " 'called': 96,\n",
       " 'quarrymen': 97,\n",
       " '1956': 98,\n",
       " 'joined': 99,\n",
       " 'guitarist': 100,\n",
       " '1957': 101,\n",
       " 'fourteenyear': 102,\n",
       " 'old': 103,\n",
       " 'though': 104,\n",
       " 'skilled': 105,\n",
       " 'did': 106,\n",
       " 'not': 107,\n",
       " 'initially': 108,\n",
       " 'impress': 109,\n",
       " 'seventeenyearold': 110,\n",
       " 'but': 111,\n",
       " 'eventually': 112,\n",
       " 'won': 113,\n",
       " 'permanent': 114,\n",
       " 'spot': 115,\n",
       " 'developing': 116,\n",
       " 'went': 117,\n",
       " 'through': 118,\n",
       " 'several': 119,\n",
       " 'additional': 120,\n",
       " 'well': 121,\n",
       " 'name': 122,\n",
       " 'changes': 123,\n",
       " 'after': 124,\n",
       " 'they': 125,\n",
       " 'became': 126,\n",
       " 'johnny': 127,\n",
       " 'moondogs': 128,\n",
       " 'themselves': 129,\n",
       " 'silver': 130,\n",
       " 'simply': 131,\n",
       " 'played': 132,\n",
       " 'only': 133,\n",
       " 'also': 134,\n",
       " 'scotland': 135,\n",
       " 'hamburg': 136,\n",
       " 'germany': 137,\n",
       " '1960': 138,\n",
       " 'bass': 139,\n",
       " 'player': 140,\n",
       " 'stu': 141,\n",
       " 'sutcliffe': 142,\n",
       " 'decided': 143,\n",
       " 'to': 144,\n",
       " 'leave': 145,\n",
       " 'took': 146,\n",
       " 'over': 147,\n",
       " 'instrument': 148,\n",
       " 'upon': 149,\n",
       " 'their': 150,\n",
       " 'return': 151,\n",
       " 'record': 152,\n",
       " 'shop': 153,\n",
       " 'manager': 154,\n",
       " 'named': 155,\n",
       " 'brian': 156,\n",
       " 'epstein': 157,\n",
       " 'approached': 158,\n",
       " 'about': 159,\n",
       " 'becoming': 160,\n",
       " 'within': 161,\n",
       " 'year': 162,\n",
       " 'signing': 163,\n",
       " 'gained': 164,\n",
       " 'recording': 165,\n",
       " 'contract': 166,\n",
       " 'emi': 167,\n",
       " 'records': 168,\n",
       " 'producer': 169,\n",
       " 'martin': 170,\n",
       " 'drummer': 171,\n",
       " 'pete': 172,\n",
       " 'best': 173,\n",
       " 'left': 174,\n",
       " 'sadeyed': 175,\n",
       " 'starkey': 176,\n",
       " 'better': 177,\n",
       " 'despite': 178,\n",
       " 'initial': 179,\n",
       " 'doubts': 180,\n",
       " 'agreed': 181,\n",
       " 'use': 182,\n",
       " 'originals': 183,\n",
       " 'both': 184,\n",
       " 'sides': 185,\n",
       " 'first': 186,\n",
       " 'single': 187,\n",
       " 'love': 188,\n",
       " 'me': 189,\n",
       " 'do': 190,\n",
       " 'released': 191,\n",
       " 'october': 192,\n",
       " '5': 193,\n",
       " '1962': 194,\n",
       " 'convinced': 195,\n",
       " 'right': 196,\n",
       " 'material': 197,\n",
       " 'could': 198,\n",
       " 'achieve': 199,\n",
       " 'number': 200,\n",
       " 'he': 201,\n",
       " 'proven': 202,\n",
       " 'correct': 203,\n",
       " 'please': 204,\n",
       " 'britain': 205,\n",
       " 'january': 206,\n",
       " '12': 207,\n",
       " '1963': 208,\n",
       " 'immediate': 209,\n",
       " 'hit': 210,\n",
       " 'album': 211,\n",
       " 'recorded': 212,\n",
       " 'thirteenhour': 213,\n",
       " 'session': 214,\n",
       " 'remained': 215,\n",
       " 'charts': 216,\n",
       " 'for': 217,\n",
       " 'six': 218,\n",
       " 'months': 219,\n",
       " 'united': 220,\n",
       " 'states': 221,\n",
       " 'uninterested': 222,\n",
       " 'until': 223,\n",
       " 'month': 224,\n",
       " 'before': 225,\n",
       " 'arrival': 226,\n",
       " 'emis': 227,\n",
       " 'company': 228,\n",
       " 'capitol': 229,\n",
       " 'launched': 230,\n",
       " 'unprecedented': 231,\n",
       " 'never': 232,\n",
       " 'done': 233,\n",
       " 'fifty': 234,\n",
       " 'thousand': 235,\n",
       " 'dollar': 236,\n",
       " 'promotional': 237,\n",
       " 'campaign': 238,\n",
       " 'publicity': 239,\n",
       " 'touropening': 240,\n",
       " 'performance': 241,\n",
       " 'ed': 242,\n",
       " 'sullivan': 243,\n",
       " 'show': 244,\n",
       " 'most': 245,\n",
       " 'entertainment': 246,\n",
       " 'television': 247,\n",
       " 'at': 248,\n",
       " 'paid': 249,\n",
       " 'off': 250,\n",
       " 'handsomely': 251,\n",
       " 'given': 252,\n",
       " 'nicknames': 253,\n",
       " 'fab': 254,\n",
       " 'mop': 255,\n",
       " 'tops': 256,\n",
       " 'because': 257,\n",
       " 'hair': 258,\n",
       " 'styles': 259,\n",
       " 'devotion': 260,\n",
       " 'fans': 261,\n",
       " 'beatlemania': 262,\n",
       " 'i': 263,\n",
       " 'want': 264,\n",
       " 'hold': 265,\n",
       " 'your': 266,\n",
       " 'hand': 267,\n",
       " '1964': 268,\n",
       " 'weeks': 269,\n",
       " 'seven': 270,\n",
       " 'top': 271,\n",
       " 'dropped': 272,\n",
       " 'two': 273,\n",
       " 'make': 274,\n",
       " 'room': 275,\n",
       " 'she': 276,\n",
       " 'loves': 277,\n",
       " 'you': 278,\n",
       " 'which': 279,\n",
       " 'gave': 280,\n",
       " 'way': 281,\n",
       " 'cant': 282,\n",
       " 'buy': 283,\n",
       " 'many': 284,\n",
       " 'week': 285,\n",
       " 'april': 286,\n",
       " '4': 287,\n",
       " 'held': 288,\n",
       " 'five': 289,\n",
       " 'slots': 290,\n",
       " 'billboard': 291,\n",
       " 'industry': 292,\n",
       " 'publication': 293,\n",
       " 'list': 294,\n",
       " 'sellers': 295,\n",
       " 'another': 296,\n",
       " 'hundred': 297,\n",
       " 'plus': 298,\n",
       " 'positions': 299,\n",
       " 'including': 300,\n",
       " 'fourteen': 301,\n",
       " 'beatles—a': 302,\n",
       " 'feat': 303,\n",
       " 'been': 304,\n",
       " 'matched': 305,\n",
       " 'nor': 306,\n",
       " 'has': 307,\n",
       " 'since': 308,\n",
       " 'appeared': 309,\n",
       " 'innovative': 310,\n",
       " 'fulllength': 311,\n",
       " 'feature': 312,\n",
       " 'films': 313,\n",
       " 'shot': 314,\n",
       " 'blackandwhite': 315,\n",
       " 'wellreceived': 316,\n",
       " 'critics': 317,\n",
       " 'hard': 318,\n",
       " 'days': 319,\n",
       " 'night': 320,\n",
       " 'fictional': 321,\n",
       " 'representation': 322,\n",
       " 'day': 323,\n",
       " 'life': 324,\n",
       " 'loved': 325,\n",
       " 'help': 326,\n",
       " 'july': 327,\n",
       " '1965': 328,\n",
       " 'madcap': 329,\n",
       " 'recklessly': 330,\n",
       " 'foolish': 331,\n",
       " 'fantasy': 332,\n",
       " 'filmed': 333,\n",
       " 'color': 334,\n",
       " 'exotic': 335,\n",
       " 'locations': 336,\n",
       " 'europe': 337,\n",
       " 'bahamas': 338,\n",
       " 'made': 339,\n",
       " 'visually': 340,\n",
       " 'more': 341,\n",
       " 'interesting': 342,\n",
       " 'than': 343,\n",
       " 'film': 344,\n",
       " 'less': 345,\n",
       " 'impressed': 346,\n",
       " '1966': 347,\n",
       " 'albums': 348,\n",
       " 'rubber': 349,\n",
       " 'soul': 350,\n",
       " 'revolver': 351,\n",
       " 'marked': 352,\n",
       " 'turning': 353,\n",
       " 'point': 354,\n",
       " 'bands': 355,\n",
       " 'history': 356,\n",
       " 'original': 357,\n",
       " 'date': 358,\n",
       " 'combined': 359,\n",
       " 'eastern': 360,\n",
       " 'countrywestern': 361,\n",
       " 'classical': 362,\n",
       " 'motifs': 363,\n",
       " 'trendsetting': 364,\n",
       " 'covers': 365,\n",
       " 'breaking': 366,\n",
       " 'any': 367,\n",
       " 'mold': 368,\n",
       " 'seemed': 369,\n",
       " 'define': 370,\n",
       " 'rock': 371,\n",
       " 'roll': 372,\n",
       " 'balladry': 373,\n",
       " 'tell': 374,\n",
       " 'stories': 375,\n",
       " 'instrumentation': 376,\n",
       " 'structure': 377,\n",
       " 'resulted': 378,\n",
       " 'brilliant': 379,\n",
       " 'concepts': 380,\n",
       " 'tomorrow': 381,\n",
       " 'knows': 382,\n",
       " 'eleanor': 383,\n",
       " 'rigby': 384,\n",
       " 'lyrical': 385,\n",
       " 'norwegian': 386,\n",
       " 'wood': 387,\n",
       " 'sophisticated': 388,\n",
       " 'subtle': 389,\n",
       " 'complex': 390,\n",
       " 'techniques': 391,\n",
       " 'this': 392,\n",
       " 'beginning': 393,\n",
       " 'end': 394,\n",
       " 'touring': 395,\n",
       " 'live': 396,\n",
       " 'performances': 397,\n",
       " 'technically': 398,\n",
       " 'impossible': 399,\n",
       " 'further': 400,\n",
       " 'distanced': 401,\n",
       " 'interview': 402,\n",
       " 'london': 403,\n",
       " 'evening': 404,\n",
       " 'standard': 405,\n",
       " 'writer': 406,\n",
       " 'said': 407,\n",
       " 'jesus': 408,\n",
       " 'christ': 409,\n",
       " 'now': 410,\n",
       " 'misunderstood': 411,\n",
       " 'some': 412,\n",
       " 'teenagers': 413,\n",
       " 'lennons': 414,\n",
       " 'words': 415,\n",
       " 'literally': 416,\n",
       " 'however': 417,\n",
       " 'burned': 418,\n",
       " 'finished': 419,\n",
       " 'last': 420,\n",
       " 'tour': 421,\n",
       " 'amid': 422,\n",
       " 'riots': 423,\n",
       " 'death': 424,\n",
       " 'threats': 425,\n",
       " 'change': 426,\n",
       " 'acclaimed': 427,\n",
       " 'advance': 428,\n",
       " 'sales': 429,\n",
       " 'million': 430,\n",
       " 'sgt': 431,\n",
       " 'peppers': 432,\n",
       " 'lonely': 433,\n",
       " 'hearts': 434,\n",
       " 'club': 435,\n",
       " '1967': 436,\n",
       " 'perhaps': 437,\n",
       " 'high': 438,\n",
       " 'career': 439,\n",
       " 'collection': 440,\n",
       " 'lennonmccartney': 441,\n",
       " 'presented': 442,\n",
       " 'stunning': 443,\n",
       " 'evocative': 444,\n",
       " 'package': 445,\n",
       " 'thematically': 446,\n",
       " 'everything': 447,\n",
       " 'related': 448,\n",
       " 'idea': 449,\n",
       " 'whole': 450,\n",
       " 'artistically': 451,\n",
       " 'pleasing': 452,\n",
       " 'believe': 453,\n",
       " 'will': 454,\n",
       " 'timeless': 455,\n",
       " 'contains': 456,\n",
       " 'imaginative': 457,\n",
       " 'melodies': 458,\n",
       " 'experiences': 459,\n",
       " 'philosophy': 460,\n",
       " 'unusual': 461,\n",
       " 'imagery': 462,\n",
       " 'evolved': 463,\n",
       " 'catchy': 464,\n",
       " 'profound': 465,\n",
       " 'ballads': 466,\n",
       " 'social': 467,\n",
       " 'commentary': 468,\n",
       " 'trying': 469,\n",
       " 'things': 470,\n",
       " 'be': 471,\n",
       " 'essential': 472,\n",
       " 'part': 473,\n",
       " 'lives': 474,\n",
       " 'greatly': 475,\n",
       " 'harrisons': 476,\n",
       " 'india': 477,\n",
       " 'visited': 478,\n",
       " 'maharishi': 479,\n",
       " 'mahesh': 480,\n",
       " 'yogi': 481,\n",
       " 'long': 482,\n",
       " 'winding': 483,\n",
       " 'road': 484,\n",
       " 'down': 485,\n",
       " 'next': 486,\n",
       " 'cooperative': 487,\n",
       " 'project': 488,\n",
       " 'scripting': 489,\n",
       " 'directing': 490,\n",
       " 'magical': 491,\n",
       " 'mystery': 492,\n",
       " 'broadcasting': 493,\n",
       " 'bbc': 494,\n",
       " 'unrehearsed': 495,\n",
       " 'unorganized': 496,\n",
       " 'failure': 497,\n",
       " 'intended': 498,\n",
       " 'fresh': 499,\n",
       " 'drew': 500,\n",
       " 'criticism': 501,\n",
       " 'compilation': 502,\n",
       " 'adolescent': 503,\n",
       " 'humor': 504,\n",
       " 'gag': 505,\n",
       " 'bits': 506,\n",
       " 'undisciplined': 507,\n",
       " 'boredom': 508,\n",
       " 'accompanying': 509,\n",
       " 'featured': 510,\n",
       " 'polished': 511,\n",
       " 'studio': 512,\n",
       " 'numbers': 513,\n",
       " 'mccartneys': 514,\n",
       " 'fool': 515,\n",
       " 'hill': 516,\n",
       " 'am': 517,\n",
       " 'walrus': 518,\n",
       " 'penny': 519,\n",
       " 'lane': 520,\n",
       " 'hello': 521,\n",
       " 'goodbye': 522,\n",
       " 'strawberry': 523,\n",
       " 'fields': 524,\n",
       " 'growing': 525,\n",
       " 'differences': 526,\n",
       " 'between': 527,\n",
       " 'artistic': 528,\n",
       " 'approaches': 529,\n",
       " 'pointed': 530,\n",
       " 'up': 531,\n",
       " '1968': 532,\n",
       " 'tworecord': 533,\n",
       " 'set': 534,\n",
       " 'apple': 535,\n",
       " 'white': 536,\n",
       " 'commonly': 537,\n",
       " 'variety': 538,\n",
       " 'no': 539,\n",
       " 'connection': 540,\n",
       " 'each': 541,\n",
       " 'other': 542,\n",
       " 'felt': 543,\n",
       " 'often': 544,\n",
       " 'difficult': 545,\n",
       " 'understand': 546,\n",
       " 'there': 547,\n",
       " 'particularly': 548,\n",
       " 'break': 549,\n",
       " 'contributed': 550,\n",
       " 'like': 551,\n",
       " 'blackbird': 552,\n",
       " 'while': 553,\n",
       " 'antiwar': 554,\n",
       " 'statements': 555,\n",
       " 'revolution': 556,\n",
       " 'fun': 557,\n",
       " 'shone': 558,\n",
       " 'my': 559,\n",
       " 'guitar': 560,\n",
       " 'gently': 561,\n",
       " 'weeps': 562,\n",
       " 'aided': 563,\n",
       " 'eric': 564,\n",
       " 'claptons': 565,\n",
       " 'tasteful': 566,\n",
       " 'solo': 567,\n",
       " 'allotted': 568,\n",
       " 'space': 569,\n",
       " 'dont': 570,\n",
       " 'pass': 571,\n",
       " 'numberone': 572,\n",
       " 'scandinavia': 573,\n",
       " 'northern': 574,\n",
       " 'where': 575,\n",
       " 'animated': 576,\n",
       " 'yellow': 577,\n",
       " 'submarine': 578,\n",
       " 'battling': 579,\n",
       " 'against': 580,\n",
       " 'blue': 581,\n",
       " 'meanies': 582,\n",
       " 'much': 583,\n",
       " 'money': 584,\n",
       " 'remainder': 585,\n",
       " '1969': 586,\n",
       " 'saw': 587,\n",
       " 'individual': 588,\n",
       " 'continuing': 589,\n",
       " 'work': 590,\n",
       " 'apart': 591,\n",
       " 'magic': 592,\n",
       " 'christian': 593,\n",
       " 'performed': 594,\n",
       " 'outside': 595,\n",
       " 'plastic': 596,\n",
       " 'ono': 597,\n",
       " 'wife': 598,\n",
       " 'yoko': 599,\n",
       " '1933–': 600,\n",
       " 'works': 601,\n",
       " 'spent': 602,\n",
       " 'filming': 603,\n",
       " 'let': 604,\n",
       " 'supposed': 605,\n",
       " 'how': 606,\n",
       " 'worked': 607,\n",
       " 'together': 608,\n",
       " 'ended': 609,\n",
       " 'showing': 610,\n",
       " 'falling': 611,\n",
       " 'editing': 612,\n",
       " 'would': 613,\n",
       " 'have': 614,\n",
       " '1970': 615,\n",
       " 'so': 616,\n",
       " 'put': 617,\n",
       " 'instead': 618,\n",
       " 'final': 619,\n",
       " 'gathered': 620,\n",
       " 'produce': 621,\n",
       " 'we': 622,\n",
       " 'quoted': 623,\n",
       " 'philip': 624,\n",
       " 'normans': 625,\n",
       " 'book': 626,\n",
       " 'shout': 627,\n",
       " 'result': 628,\n",
       " 'pepper': 629,\n",
       " 'problems': 630,\n",
       " 'vanish': 631,\n",
       " 'abbey': 632,\n",
       " 'contained': 633,\n",
       " 'classics': 634,\n",
       " 'come': 635,\n",
       " 'golden': 636,\n",
       " 'slumbers': 637,\n",
       " 'octopuss': 638,\n",
       " 'garden': 639,\n",
       " 'here': 640,\n",
       " 'comes': 641,\n",
       " 'sun': 642,\n",
       " 'something': 643,\n",
       " 'hailed': 644,\n",
       " 'track': 645,\n",
       " 'yet': 646,\n",
       " 'grammy': 647,\n",
       " 'award': 648,\n",
       " 'phil': 649,\n",
       " 'spector': 650,\n",
       " 'resulting': 651,\n",
       " '1971': 652,\n",
       " 'got': 653,\n",
       " 'mixed': 654,\n",
       " 'reviews': 655,\n",
       " 'seen': 656,\n",
       " 'quarreling': 657,\n",
       " 'unresponsive': 658,\n",
       " 'attempts': 659,\n",
       " 'raise': 660,\n",
       " 'morale': 661,\n",
       " 'spirit': 662,\n",
       " 'sued': 663,\n",
       " 'legally': 664,\n",
       " 'throughout': 665,\n",
       " '1970s': 666,\n",
       " 'promoters': 667,\n",
       " 'attempted': 668,\n",
       " 'reunite': 669,\n",
       " 'without': 670,\n",
       " 'success': 671,\n",
       " 'mark': 672,\n",
       " 'david': 673,\n",
       " 'chapman': 674,\n",
       " 'murdered': 675,\n",
       " 'december': 676,\n",
       " '8': 677,\n",
       " '1980': 678,\n",
       " 'york': 679,\n",
       " 'city': 680,\n",
       " 'under': 681,\n",
       " 'remaining': 682,\n",
       " 'tape': 683,\n",
       " 'singles': 684,\n",
       " 'free': 685,\n",
       " 'bird': 686,\n",
       " 'real': 687,\n",
       " 'parts': 688,\n",
       " 'featuring': 689,\n",
       " 'earlier': 690,\n",
       " 'sessions': 691,\n",
       " 'died': 692,\n",
       " 'november': 693,\n",
       " '29': 694,\n",
       " '2001': 695,\n",
       " 'los': 696,\n",
       " 'angeles': 697,\n",
       " 'california': 698,\n",
       " 'brain': 699,\n",
       " 'cancer': 700,\n",
       " 'continue': 701,\n",
       " 'major': 702,\n",
       " 'influence': 703,\n",
       " 'creation': 704,\n",
       " 'modern': 705,\n",
       " 'inducted': 706,\n",
       " 'into': 707,\n",
       " 'hall': 708,\n",
       " 'fame': 709,\n",
       " '1988': 710,\n",
       " 'performers': 711}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_vocab, b_collection = doc_vocab('beatles_biography.txt')\n",
    "b_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 7., 1., ..., 0., 0., 0.],\n",
       "       [1., 3., 0., ..., 0., 0., 0.],\n",
       "       [7., 9., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [3., 5., 0., ..., 0., 0., 0.],\n",
       "       [2., 4., 0., ..., 0., 0., 0.],\n",
       "       [4., 4., 0., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_doc_term_mat = doc_term_matrix(vocabulary=b_vocab, collection=b_collection)\n",
    "b_doc_term_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03448276, 0.12068966, 0.01724138, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01492537, 0.04477612, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07      , 0.09      , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.04225352, 0.07042254, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.03225806, 0.06451613, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.05882353, 0.05882353, 0.        , ..., 0.01470588, 0.01470588,\n",
       "        0.01470588]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tf_mat = tf_matrix(b_doc_term_mat)\n",
    "b_tf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00166568, 0.        , 0.02204748, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00072097, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00338133, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.00204104, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00155822, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00284145, 0.        , 0.        , ..., 0.0188052 , 0.0188052 ,\n",
       "        0.0188052 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tf_idf = tf_idf_matrix(b_doc_term_mat, b_tf_mat)\n",
    "b_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART I: build lexicon and document collection\n",
    "def doc_vocab_v2(filename):\n",
    "    \n",
    "    collection = list(); lexicon = dict()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.translate(str.maketrans('', '', string.punctuation)).lower().strip() #remove punctuation           \n",
    "            re_sw = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\") #regex to remove stopwords\n",
    "            line = re_sw.sub(\"\", line) #remove stopwords\n",
    "            collection.append(line)\n",
    "            tokenized_sent = line.split()\n",
    "            \n",
    "            \n",
    "            for word in tokenized_sent:\n",
    "                if word not in lexicon and word not in stop_words:\n",
    "                    lexicon[word] = len(lexicon)\n",
    "    \n",
    "            \n",
    "    # you may import libraries and define additional helper functions outside this function\n",
    "    # lexicon is a synonym for vocabulary\n",
    "    \n",
    "    return lexicon, collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1960s': 0,\n",
       " 'new': 1,\n",
       " 'band': 2,\n",
       " 'known': 3,\n",
       " 'beatles': 4,\n",
       " 'burst': 5,\n",
       " 'pop': 6,\n",
       " 'music': 7,\n",
       " 'scene': 8,\n",
       " 'changed': 9,\n",
       " 'forever': 10,\n",
       " 'members': 11,\n",
       " 'included': 12,\n",
       " 'george': 13,\n",
       " 'harrison': 14,\n",
       " '1943–2001': 15,\n",
       " 'john': 16,\n",
       " 'lennon': 17,\n",
       " '1940–1980': 18,\n",
       " 'paul': 19,\n",
       " 'mccartney': 20,\n",
       " '1942–': 21,\n",
       " 'ringo': 22,\n",
       " 'starr': 23,\n",
       " '1940–': 24,\n",
       " 'release': 25,\n",
       " 'three': 26,\n",
       " 'anthologies': 27,\n",
       " 'collections': 28,\n",
       " 'mid1990s': 29,\n",
       " 'remain': 30,\n",
       " 'one': 31,\n",
       " 'bestselling': 32,\n",
       " 'musical': 33,\n",
       " 'groups': 34,\n",
       " 'time': 35,\n",
       " 'came': 36,\n",
       " 'liverpool': 37,\n",
       " 'england': 38,\n",
       " 'originally': 39,\n",
       " 'inspired': 40,\n",
       " 'simple': 41,\n",
       " 'guitarandwashboard': 42,\n",
       " 'style': 43,\n",
       " 'skiffle': 44,\n",
       " 'lively': 45,\n",
       " 'type': 46,\n",
       " 'acoustic': 47,\n",
       " 'nonelectric': 48,\n",
       " 'used': 49,\n",
       " 'songs': 50,\n",
       " 'british': 51,\n",
       " 'american': 52,\n",
       " 'folk': 53,\n",
       " 'popular': 54,\n",
       " 'later': 55,\n",
       " 'us': 56,\n",
       " 'artists': 57,\n",
       " 'elvis': 58,\n",
       " 'presley': 59,\n",
       " '1935–1977': 60,\n",
       " 'buddy': 61,\n",
       " 'holly': 62,\n",
       " '1936–1959': 63,\n",
       " 'little': 64,\n",
       " 'richard': 65,\n",
       " '1932–': 66,\n",
       " 'influenced': 67,\n",
       " 'four': 68,\n",
       " 'early': 69,\n",
       " 'interest': 70,\n",
       " 'started': 71,\n",
       " 'formed': 72,\n",
       " 'group': 73,\n",
       " 'called': 74,\n",
       " 'quarrymen': 75,\n",
       " '1956': 76,\n",
       " 'joined': 77,\n",
       " 'guitarist': 78,\n",
       " '1957': 79,\n",
       " 'fourteenyear': 80,\n",
       " 'old': 81,\n",
       " 'though': 82,\n",
       " 'skilled': 83,\n",
       " 'initially': 84,\n",
       " 'impress': 85,\n",
       " 'seventeenyearold': 86,\n",
       " 'eventually': 87,\n",
       " 'permanent': 88,\n",
       " 'spot': 89,\n",
       " 'developing': 90,\n",
       " 'went': 91,\n",
       " 'several': 92,\n",
       " 'additional': 93,\n",
       " 'well': 94,\n",
       " 'name': 95,\n",
       " 'changes': 96,\n",
       " 'became': 97,\n",
       " 'johnny': 98,\n",
       " 'moondogs': 99,\n",
       " 'silver': 100,\n",
       " 'simply': 101,\n",
       " 'played': 102,\n",
       " 'also': 103,\n",
       " 'scotland': 104,\n",
       " 'hamburg': 105,\n",
       " 'germany': 106,\n",
       " '1960': 107,\n",
       " 'bass': 108,\n",
       " 'player': 109,\n",
       " 'stu': 110,\n",
       " 'sutcliffe': 111,\n",
       " 'decided': 112,\n",
       " 'leave': 113,\n",
       " 'took': 114,\n",
       " 'instrument': 115,\n",
       " 'upon': 116,\n",
       " 'return': 117,\n",
       " 'record': 118,\n",
       " 'shop': 119,\n",
       " 'manager': 120,\n",
       " 'named': 121,\n",
       " 'brian': 122,\n",
       " 'epstein': 123,\n",
       " 'approached': 124,\n",
       " 'becoming': 125,\n",
       " 'within': 126,\n",
       " 'year': 127,\n",
       " 'signing': 128,\n",
       " 'gained': 129,\n",
       " 'recording': 130,\n",
       " 'contract': 131,\n",
       " 'emi': 132,\n",
       " 'records': 133,\n",
       " 'producer': 134,\n",
       " 'martin': 135,\n",
       " 'drummer': 136,\n",
       " 'pete': 137,\n",
       " 'best': 138,\n",
       " 'left': 139,\n",
       " 'sadeyed': 140,\n",
       " 'starkey': 141,\n",
       " 'better': 142,\n",
       " 'despite': 143,\n",
       " 'initial': 144,\n",
       " 'doubts': 145,\n",
       " 'agreed': 146,\n",
       " 'use': 147,\n",
       " 'originals': 148,\n",
       " 'sides': 149,\n",
       " 'first': 150,\n",
       " 'single': 151,\n",
       " 'love': 152,\n",
       " 'released': 153,\n",
       " 'october': 154,\n",
       " '5': 155,\n",
       " '1962': 156,\n",
       " 'convinced': 157,\n",
       " 'right': 158,\n",
       " 'material': 159,\n",
       " 'could': 160,\n",
       " 'achieve': 161,\n",
       " 'number': 162,\n",
       " 'proven': 163,\n",
       " 'correct': 164,\n",
       " 'please': 165,\n",
       " 'britain': 166,\n",
       " 'january': 167,\n",
       " '12': 168,\n",
       " '1963': 169,\n",
       " 'immediate': 170,\n",
       " 'hit': 171,\n",
       " 'album': 172,\n",
       " 'recorded': 173,\n",
       " 'thirteenhour': 174,\n",
       " 'session': 175,\n",
       " 'remained': 176,\n",
       " 'charts': 177,\n",
       " 'six': 178,\n",
       " 'months': 179,\n",
       " 'united': 180,\n",
       " 'states': 181,\n",
       " 'uninterested': 182,\n",
       " 'month': 183,\n",
       " 'arrival': 184,\n",
       " 'emis': 185,\n",
       " 'company': 186,\n",
       " 'capitol': 187,\n",
       " 'launched': 188,\n",
       " 'unprecedented': 189,\n",
       " 'never': 190,\n",
       " 'done': 191,\n",
       " 'fifty': 192,\n",
       " 'thousand': 193,\n",
       " 'dollar': 194,\n",
       " 'promotional': 195,\n",
       " 'campaign': 196,\n",
       " 'publicity': 197,\n",
       " 'touropening': 198,\n",
       " 'performance': 199,\n",
       " 'ed': 200,\n",
       " 'sullivan': 201,\n",
       " 'show': 202,\n",
       " 'entertainment': 203,\n",
       " 'television': 204,\n",
       " 'paid': 205,\n",
       " 'handsomely': 206,\n",
       " 'given': 207,\n",
       " 'nicknames': 208,\n",
       " 'fab': 209,\n",
       " 'mop': 210,\n",
       " 'tops': 211,\n",
       " 'hair': 212,\n",
       " 'styles': 213,\n",
       " 'devotion': 214,\n",
       " 'fans': 215,\n",
       " 'beatlemania': 216,\n",
       " 'want': 217,\n",
       " 'hold': 218,\n",
       " 'hand': 219,\n",
       " '1964': 220,\n",
       " 'weeks': 221,\n",
       " 'seven': 222,\n",
       " 'top': 223,\n",
       " 'dropped': 224,\n",
       " 'two': 225,\n",
       " 'make': 226,\n",
       " 'room': 227,\n",
       " 'loves': 228,\n",
       " 'gave': 229,\n",
       " 'way': 230,\n",
       " 'cant': 231,\n",
       " 'buy': 232,\n",
       " 'many': 233,\n",
       " 'week': 234,\n",
       " 'april': 235,\n",
       " '4': 236,\n",
       " 'held': 237,\n",
       " 'five': 238,\n",
       " 'slots': 239,\n",
       " 'billboard': 240,\n",
       " 'industry': 241,\n",
       " 'publication': 242,\n",
       " 'list': 243,\n",
       " 'sellers': 244,\n",
       " 'another': 245,\n",
       " 'hundred': 246,\n",
       " 'plus': 247,\n",
       " 'positions': 248,\n",
       " 'including': 249,\n",
       " 'fourteen': 250,\n",
       " 'beatles—feat': 251,\n",
       " 'matched': 252,\n",
       " 'since': 253,\n",
       " 'appeared': 254,\n",
       " 'innovative': 255,\n",
       " 'fulllength': 256,\n",
       " 'feature': 257,\n",
       " 'films': 258,\n",
       " 'shot': 259,\n",
       " 'blackandwhite': 260,\n",
       " 'wellreceived': 261,\n",
       " 'critics': 262,\n",
       " 'hard': 263,\n",
       " 'days': 264,\n",
       " 'night': 265,\n",
       " 'fictional': 266,\n",
       " 'representation': 267,\n",
       " 'day': 268,\n",
       " 'life': 269,\n",
       " 'loved': 270,\n",
       " 'help': 271,\n",
       " 'july': 272,\n",
       " '1965': 273,\n",
       " 'madcap': 274,\n",
       " 'recklessly': 275,\n",
       " 'foolish': 276,\n",
       " 'fantasy': 277,\n",
       " 'filmed': 278,\n",
       " 'color': 279,\n",
       " 'exotic': 280,\n",
       " 'locations': 281,\n",
       " 'europe': 282,\n",
       " 'bahamas': 283,\n",
       " 'made': 284,\n",
       " 'visually': 285,\n",
       " 'interesting': 286,\n",
       " 'film': 287,\n",
       " 'less': 288,\n",
       " 'impressed': 289,\n",
       " '1966': 290,\n",
       " 'albums': 291,\n",
       " 'rubber': 292,\n",
       " 'soul': 293,\n",
       " 'revolver': 294,\n",
       " 'marked': 295,\n",
       " 'turning': 296,\n",
       " 'point': 297,\n",
       " 'bands': 298,\n",
       " 'history': 299,\n",
       " 'original': 300,\n",
       " 'date': 301,\n",
       " 'combined': 302,\n",
       " 'eastern': 303,\n",
       " 'countrywestern': 304,\n",
       " 'classical': 305,\n",
       " 'motifs': 306,\n",
       " 'trendsetting': 307,\n",
       " 'covers': 308,\n",
       " 'breaking': 309,\n",
       " 'mold': 310,\n",
       " 'seemed': 311,\n",
       " 'define': 312,\n",
       " 'rock': 313,\n",
       " 'roll': 314,\n",
       " 'balladry': 315,\n",
       " 'tell': 316,\n",
       " 'stories': 317,\n",
       " 'instrumentation': 318,\n",
       " 'structure': 319,\n",
       " 'resulted': 320,\n",
       " 'brilliant': 321,\n",
       " 'concepts': 322,\n",
       " 'tomorrow': 323,\n",
       " 'knows': 324,\n",
       " 'eleanor': 325,\n",
       " 'rigby': 326,\n",
       " 'lyrical': 327,\n",
       " 'norwegian': 328,\n",
       " 'wood': 329,\n",
       " 'sophisticated': 330,\n",
       " 'subtle': 331,\n",
       " 'complex': 332,\n",
       " 'techniques': 333,\n",
       " 'beginning': 334,\n",
       " 'end': 335,\n",
       " 'touring': 336,\n",
       " 'live': 337,\n",
       " 'performances': 338,\n",
       " 'technically': 339,\n",
       " 'impossible': 340,\n",
       " 'distanced': 341,\n",
       " 'interview': 342,\n",
       " 'london': 343,\n",
       " 'evening': 344,\n",
       " 'standard': 345,\n",
       " 'writer': 346,\n",
       " 'said': 347,\n",
       " 'jesus': 348,\n",
       " 'christ': 349,\n",
       " 'misunderstood': 350,\n",
       " 'teenagers': 351,\n",
       " 'lennons': 352,\n",
       " 'words': 353,\n",
       " 'literally': 354,\n",
       " 'however': 355,\n",
       " 'burned': 356,\n",
       " 'finished': 357,\n",
       " 'last': 358,\n",
       " 'tour': 359,\n",
       " 'amid': 360,\n",
       " 'riots': 361,\n",
       " 'death': 362,\n",
       " 'threats': 363,\n",
       " 'change': 364,\n",
       " 'acclaimed': 365,\n",
       " 'advance': 366,\n",
       " 'sales': 367,\n",
       " 'million': 368,\n",
       " 'sgt': 369,\n",
       " 'peppers': 370,\n",
       " 'lonely': 371,\n",
       " 'hearts': 372,\n",
       " 'club': 373,\n",
       " '1967': 374,\n",
       " 'perhaps': 375,\n",
       " 'high': 376,\n",
       " 'career': 377,\n",
       " 'collection': 378,\n",
       " 'lennonmccartney': 379,\n",
       " 'presented': 380,\n",
       " 'stunning': 381,\n",
       " 'evocative': 382,\n",
       " 'package': 383,\n",
       " 'thematically': 384,\n",
       " 'everything': 385,\n",
       " 'related': 386,\n",
       " 'idea': 387,\n",
       " 'whole': 388,\n",
       " 'artistically': 389,\n",
       " 'pleasing': 390,\n",
       " 'believe': 391,\n",
       " 'timeless': 392,\n",
       " 'contains': 393,\n",
       " 'imaginative': 394,\n",
       " 'melodies': 395,\n",
       " 'experiences': 396,\n",
       " 'philosophy': 397,\n",
       " 'unusual': 398,\n",
       " 'imagery': 399,\n",
       " 'evolved': 400,\n",
       " 'catchy': 401,\n",
       " 'profound': 402,\n",
       " 'ballads': 403,\n",
       " 'social': 404,\n",
       " 'commentary': 405,\n",
       " 'trying': 406,\n",
       " 'things': 407,\n",
       " 'essential': 408,\n",
       " 'part': 409,\n",
       " 'lives': 410,\n",
       " 'greatly': 411,\n",
       " 'harrisons': 412,\n",
       " 'india': 413,\n",
       " 'visited': 414,\n",
       " 'maharishi': 415,\n",
       " 'mahesh': 416,\n",
       " 'yogi': 417,\n",
       " 'long': 418,\n",
       " 'winding': 419,\n",
       " 'road': 420,\n",
       " 'next': 421,\n",
       " 'cooperative': 422,\n",
       " 'project': 423,\n",
       " 'scripting': 424,\n",
       " 'directing': 425,\n",
       " 'magical': 426,\n",
       " 'mystery': 427,\n",
       " 'broadcasting': 428,\n",
       " 'bbc': 429,\n",
       " 'unrehearsed': 430,\n",
       " 'unorganized': 431,\n",
       " 'failure': 432,\n",
       " 'intended': 433,\n",
       " 'fresh': 434,\n",
       " 'drew': 435,\n",
       " 'criticism': 436,\n",
       " 'compilation': 437,\n",
       " 'adolescent': 438,\n",
       " 'humor': 439,\n",
       " 'gag': 440,\n",
       " 'bits': 441,\n",
       " 'undisciplined': 442,\n",
       " 'boredom': 443,\n",
       " 'accompanying': 444,\n",
       " 'featured': 445,\n",
       " 'polished': 446,\n",
       " 'studio': 447,\n",
       " 'numbers': 448,\n",
       " 'mccartneys': 449,\n",
       " 'fool': 450,\n",
       " 'hill': 451,\n",
       " 'walrus': 452,\n",
       " 'penny': 453,\n",
       " 'lane': 454,\n",
       " 'hello': 455,\n",
       " 'goodbye': 456,\n",
       " 'strawberry': 457,\n",
       " 'fields': 458,\n",
       " 'growing': 459,\n",
       " 'differences': 460,\n",
       " 'artistic': 461,\n",
       " 'approaches': 462,\n",
       " 'pointed': 463,\n",
       " '1968': 464,\n",
       " 'tworecord': 465,\n",
       " 'set': 466,\n",
       " 'apple': 467,\n",
       " 'white': 468,\n",
       " 'commonly': 469,\n",
       " 'variety': 470,\n",
       " 'connection': 471,\n",
       " 'felt': 472,\n",
       " 'often': 473,\n",
       " 'difficult': 474,\n",
       " 'understand': 475,\n",
       " 'particularly': 476,\n",
       " 'break': 477,\n",
       " 'contributed': 478,\n",
       " 'like': 479,\n",
       " 'blackbird': 480,\n",
       " 'antiwar': 481,\n",
       " 'statements': 482,\n",
       " 'revolution': 483,\n",
       " 'fun': 484,\n",
       " 'shone': 485,\n",
       " 'guitar': 486,\n",
       " 'gently': 487,\n",
       " 'weeps': 488,\n",
       " 'aided': 489,\n",
       " 'eric': 490,\n",
       " 'claptons': 491,\n",
       " 'tasteful': 492,\n",
       " 'solo': 493,\n",
       " 'allotted': 494,\n",
       " 'space': 495,\n",
       " 'dont': 496,\n",
       " 'pass': 497,\n",
       " 'numberone': 498,\n",
       " 'scandinavia': 499,\n",
       " 'northern': 500,\n",
       " 'animated': 501,\n",
       " 'yellow': 502,\n",
       " 'submarine': 503,\n",
       " 'battling': 504,\n",
       " 'blue': 505,\n",
       " 'meanies': 506,\n",
       " 'much': 507,\n",
       " 'money': 508,\n",
       " 'remainder': 509,\n",
       " '1969': 510,\n",
       " 'saw': 511,\n",
       " 'individual': 512,\n",
       " 'continuing': 513,\n",
       " 'work': 514,\n",
       " 'apart': 515,\n",
       " 'magic': 516,\n",
       " 'christian': 517,\n",
       " 'performed': 518,\n",
       " 'outside': 519,\n",
       " 'plastic': 520,\n",
       " 'ono': 521,\n",
       " 'wife': 522,\n",
       " 'yoko': 523,\n",
       " '1933–': 524,\n",
       " 'works': 525,\n",
       " 'spent': 526,\n",
       " 'filming': 527,\n",
       " 'let': 528,\n",
       " 'supposed': 529,\n",
       " 'worked': 530,\n",
       " 'together': 531,\n",
       " 'ended': 532,\n",
       " 'showing': 533,\n",
       " 'falling': 534,\n",
       " 'editing': 535,\n",
       " 'would': 536,\n",
       " '1970': 537,\n",
       " 'put': 538,\n",
       " 'instead': 539,\n",
       " 'final': 540,\n",
       " 'gathered': 541,\n",
       " 'produce': 542,\n",
       " 'quoted': 543,\n",
       " 'philip': 544,\n",
       " 'normans': 545,\n",
       " 'book': 546,\n",
       " 'shout': 547,\n",
       " 'result': 548,\n",
       " 'pepper': 549,\n",
       " 'problems': 550,\n",
       " 'vanish': 551,\n",
       " 'abbey': 552,\n",
       " 'contained': 553,\n",
       " 'classics': 554,\n",
       " 'come': 555,\n",
       " 'golden': 556,\n",
       " 'slumbers': 557,\n",
       " 'octopuss': 558,\n",
       " 'garden': 559,\n",
       " 'comes': 560,\n",
       " 'sun': 561,\n",
       " 'something': 562,\n",
       " 'hailed': 563,\n",
       " 'track': 564,\n",
       " 'yet': 565,\n",
       " 'grammy': 566,\n",
       " 'award': 567,\n",
       " 'phil': 568,\n",
       " 'spector': 569,\n",
       " 'resulting': 570,\n",
       " '1971': 571,\n",
       " 'got': 572,\n",
       " 'mixed': 573,\n",
       " 'reviews': 574,\n",
       " 'seen': 575,\n",
       " 'quarreling': 576,\n",
       " 'unresponsive': 577,\n",
       " 'attempts': 578,\n",
       " 'raise': 579,\n",
       " 'morale': 580,\n",
       " 'spirit': 581,\n",
       " 'sued': 582,\n",
       " 'legally': 583,\n",
       " 'throughout': 584,\n",
       " '1970s': 585,\n",
       " 'promoters': 586,\n",
       " 'attempted': 587,\n",
       " 'reunite': 588,\n",
       " 'without': 589,\n",
       " 'success': 590,\n",
       " 'mark': 591,\n",
       " 'david': 592,\n",
       " 'chapman': 593,\n",
       " 'murdered': 594,\n",
       " 'december': 595,\n",
       " '8': 596,\n",
       " '1980': 597,\n",
       " 'york': 598,\n",
       " 'city': 599,\n",
       " 'remaining': 600,\n",
       " 'tape': 601,\n",
       " 'singles': 602,\n",
       " 'free': 603,\n",
       " 'bird': 604,\n",
       " 'real': 605,\n",
       " 'parts': 606,\n",
       " 'featuring': 607,\n",
       " 'earlier': 608,\n",
       " 'sessions': 609,\n",
       " 'died': 610,\n",
       " 'november': 611,\n",
       " '29': 612,\n",
       " '2001': 613,\n",
       " 'los': 614,\n",
       " 'angeles': 615,\n",
       " 'california': 616,\n",
       " 'brain': 617,\n",
       " 'cancer': 618,\n",
       " 'continue': 619,\n",
       " 'major': 620,\n",
       " 'influence': 621,\n",
       " 'creation': 622,\n",
       " 'modern': 623,\n",
       " 'inducted': 624,\n",
       " 'hall': 625,\n",
       " 'fame': 626,\n",
       " '1988': 627,\n",
       " 'performers': 628}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_vocab_v2, b_collection_v2 = doc_vocab_v2('beatles_biography.txt')\n",
    "b_vocab_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1960s new band known beatles burst pop music scene changed forever band members included george harrison 1943–2001 john lennon 1940–1980 paul mccartney 1942– ringo starr 1940– release three anthologies collections mid1990s beatles remain one bestselling musical groups time',\n",
       " 'beatles came liverpool england originally inspired simple guitarandwashboard style skiffle music skiffle lively type acoustic nonelectric music used songs british american folk popular music later us pop artists elvis presley 1935–1977 buddy holly 1936–1959 little richard 1932– influenced four members beatles early interest music',\n",
       " 'beatles started john lennon formed group called quarrymen 1956 paul mccartney joined group guitarist 1957 fourteenyear old george harrison though skilled guitarist initially impress seventeenyearold lennon eventually permanent spot developing group beatles went several additional members well several name changes quarrymen became johnny moondogs later called silver beatles eventually simply beatles played liverpool also scotland hamburg germany 1960',\n",
       " 'beatles bass player stu sutcliffe decided leave mccartney took instrument upon return england record shop manager named brian epstein approached band becoming manager within year signing epstein manager beatles gained recording contract emi records producer george martin drummer pete best left group sadeyed drummer named richard starkey better known ringo starr joined',\n",
       " 'despite initial doubts george martin agreed use lennon mccartney originals sides beatles first single love released october 5 1962 convinced martin right material beatles could achieve number one record proven correct',\n",
       " 'beatles please please released britain january 12 1963 immediate hit beatles first british album recorded one thirteenhour session remained number one charts six months united states remained uninterested one month beatles arrival emis us company capitol records launched unprecedented never done fifty thousand dollar promotional campaign publicity beatles american touropening performance ed sullivan show popular entertainment show television time paid handsomely given nicknames fab four mop tops hair styles devotion fans called beatlemania',\n",
       " 'beatles want hold hand released united states january 1964 hit number one within three weeks seven weeks top charts dropped number two make room loves gave way cant buy love many three new songs week released april 4 1964 beatles held top five slots billboard recording industry publication list top sellers also another seven songs top one hundred plus four album positions including top two one week later fourteen top one hundred songs beatles—feat never matched since',\n",
       " 'also 1964 beatles appeared first several innovative fulllength feature films shot blackandwhite wellreceived critics hard days night fictional representation day life group critics fans loved help released july 1965 madcap recklessly foolish fantasy filmed color exotic locations europe bahamas made help visually interesting first film critics less impressed',\n",
       " 'beatles 1965 1966 albums rubber soul revolver marked turning point bands recording history original collections date combined eastern countrywestern soul classical motifs trendsetting covers breaking mold seemed define rock roll albums balladry songs tell stories classical instrumentation new structure resulted brilliant new concepts songs tomorrow never knows eleanor rigby lyrical norwegian wood made use sophisticated subtle complex recording techniques beginning end groups touring since live performances songs technically impossible time',\n",
       " 'beatles became distanced fans interview london evening standard writer lennon said popular jesus christ later lennon said misunderstood american teenagers took lennons words literally however burned beatles albums group finished last us tour amid riots death threats',\n",
       " 'change rock roll acclaimed critics advance sales one million beatles sgt peppers lonely hearts club band 1967 perhaps high point recording career simply collection lennonmccartney harrison originals presented stunning evocative album package thematically everything related one idea whole artistically pleasing critics believe remain timeless contains imaginative melodies songs many life experiences philosophy unusual imagery beatles music evolved catchy love songs profound ballads social commentary trying new things seemed essential part beatles lives influenced greatly harrisons interest india beatles visited maharishi mahesh yogi india',\n",
       " 'long winding road beatles next cooperative project scripting directing another film magical mystery tour 1967 british broadcasting company bbc unrehearsed unorganized failure intended fresh drew criticism compilation adolescent humor gag bits undisciplined boredom accompanying album however featured polished studio numbers mccartneys fool hill lennons walrus well penny lane hello goodbye strawberry fields forever included film',\n",
       " 'growing differences artistic approaches pointed beatles breaking 1968 recorded tworecord set simply called beatles first album released groups new record company apple white album commonly known variety songs connection felt often difficult understand particularly appeared growing break lennon mccartney mccartney contributed ballads like blackbird lennon gave antiwar statements like revolution made fun maharishi harrison hand shone guitar gently weeps aided eric claptons tasteful guitar solo first time starr allotted space original countrywestern dont pass became numberone hit scandinavia northern europe released single',\n",
       " 'beatles animated feature film yellow submarine released july 1968 fantasy beatles battling blue meanies film visually pleasing make much money first released',\n",
       " 'remainder 1968 1969 saw individual beatles continuing work apart starr appeared film magic christian lennon performed live outside beatles group called plastic ono band wife yoko ono 1933–',\n",
       " 'last works beatles spent months filming recording let supposed film group worked together ended film showing group falling apart editing would made release 1970 impossible project put hold instead final time beatles gathered produce album way used mccartney quoted philip normans book shout result stunning sgt pepper problems seemed vanish album abbey road 1969 beatles best album contained classics come together golden slumbers octopuss garden harrisons comes sun something lennon hailed best track album yet another grammy award',\n",
       " 'american producer phil spector 1940– took beatles let project 1970 resulting film album released 1971 got mixed reviews band members seen quarreling unresponsive mccartneys attempts raise morale spirit end 1970 four beatles recorded solo albums 1971 mccartney sued legally end group throughout 1970s promoters attempted reunite without success',\n",
       " 'mark david chapman murdered john lennon december 8 1980 new york city new york mid1990s however new music released original band name remaining beatles played songs lennon left tape singles free bird real love released parts anthologies featuring material earlier beatles recording sessions',\n",
       " 'george harrison died november 29 2001 los angeles california brain cancer paul mccartney ringo starr continue record beatles major influence rock roll also creation modern popular music beatles inducted rock roll hall fame 1988 lennon mccartney also inducted solo performers']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_collection_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b_collection_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As seen below, we have 82 stop_words in this document (712 before removing stop words and 630 after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "629"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b_vocab_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 2., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 3., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_doc_term_mat_v2 = doc_term_matrix(vocabulary=b_vocab_v2, collection=b_collection_v2)\n",
    "b_doc_term_mat_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02631579, 0.02631579, 0.05263158, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.02083333, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.06976744, 0.02325581, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.025     , 0.025     ,\n",
       "        0.025     ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tf_mat_v2 = tf_matrix(b_doc_term_mat_v2)\n",
    "b_tf_mat_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03365141, 0.01317375, 0.02634749, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.01042922, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.03492575, 0.01164192, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.03196884, 0.03196884,\n",
       "        0.03196884]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tf_idf_v2 = tf_idf_matrix(b_doc_term_mat_v2, b_tf_mat_v2)\n",
    "b_tf_idf_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The functions below are used to extract top 3 words for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3(row):\n",
    "    \"\"\"\n",
    "    Use argsort() to return a list of indexes of array in sorted order.\n",
    "    Pull the last 3 into a list(corresponding to the entries with the 3 highest tf-idf scores)\n",
    "    \"\"\"\n",
    "    return row.argsort()[-3:] \n",
    "\n",
    "def get_word(idx):\n",
    "    \"\"\"\n",
    "    Search for key associated to given numeric value. if none found, return empty string\n",
    "    \"\"\"\n",
    "    for k,v in b_vocab_v2.items():\n",
    "        if v==idx:\n",
    "            return k\n",
    "    return \"\"\n",
    "def get_words(row):\n",
    "    \"\"\"\n",
    "    Returns a list of words using get_word()\n",
    "    \"\"\"\n",
    "    return [get_word(i) for i in row]\n",
    "\n",
    "\n",
    "def top_words_by_doc():\n",
    "    top_word_idx = np.apply_along_axis(top3, axis=1, arr=b_tf_idf_v2) #Get top 3 words by tf_idf score for each doc\n",
    "    top_words = np.apply_along_axis(get_words, axis=1, arr=top_word_idx)\n",
    "    return top_words\n",
    "    \n",
    "\n",
    "top_words = top_words_by_doc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['bestselling', 'scene', '1960s'],\n",
       "       ['buddy', 'music', 'skiffle'],\n",
       "       ['eventually', 'guitarist', 'quarrymen'],\n",
       "       ['named', 'drummer', 'manager'],\n",
       "       ['right', '1962', 'martin'],\n",
       "       ['remained', 'show', 'please'],\n",
       "       ['weeks', 'week', 'top'],\n",
       "       ['days', 'help', 'critics'],\n",
       "       ['albums', 'classical', 'soul'],\n",
       "       ['distanced', 'misundersto', 'said'],\n",
       "       ['acclaimed', 'critics', 'india'],\n",
       "       ['compilation', 'bbc', 'fields'],\n",
       "       ['guitar', 'like', 'growing'],\n",
       "       ['animated', 'money', 'submarine'],\n",
       "       ['remainder', '1933–', 'ono'],\n",
       "       ['album', 'best', 'together'],\n",
       "       ['end', '1970', '1971'],\n",
       "       ['city', 'new', 'york'],\n",
       "       ['rock', 'roll', 'inducted']], dtype='<U11')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of the analysis, we have 19 documents<br>\n",
    "\"critics\" is the only complete word that appears in more than one document<br>\n",
    "However, if we had performed lemmatization, we would see that other root forms like \"remain\", \"week\", \"album\", and \n",
    "\"best\" also appear two or more times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
